{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit/blob/master/spyrit/tutorial/tuto_core_2d_short.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mbA6mRJNlX3Q"
      },
      "source": [
        "# Tutorial 2D - Image reconstruction for single-pixel imaging\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial shows how to simulate data and perform image reconstruction with spyrit toolbox for 2D single-pixel imaging. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image below displays the ground-truth image, undersampled data and reconstruction with different methods.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1zBrCKHWM-AnAL1bs6HIZZ49wztWk_rvG\" alt=\"drawing\" width=\"800\"/>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For **data simulation**, it loads an image from ImageNet and simulated measurements based on \n",
        "an undersampled Hadamard operator. You can select the number of counts and undersampled factor. \n",
        "\n",
        "**Image reconstruction** is performed using the following methods: \n",
        "-    Pseudo-inverse\n",
        "-    PInvNet:        Linear net (same result as Pseudo-inverse)\n",
        "-    DCNet:          Data completion net with unit matrix denoising\n",
        "-    DCUNet:         Data completion with UNet denoising, trained on stl10 dataset (requires to download UNet weights). "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we have adopted a simplified version for data simulation based on unit covariance and undersampling factor based on the first $M$ measurements, for simplicity. In order to replicate the results above, just set *download_cov=True*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set download data covariance to True for realistic simulations\n",
        "# It taken a few minutes to download the data\n",
        "download_cov = True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set google colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BWsO227W3jZ_"
      },
      "source": [
        "Set *mode_colab=True* to run in colab. Mount google drive, needed to import spyrit modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNKXfDpdlX3U"
      },
      "outputs": [],
      "source": [
        "mode_colab = True\n",
        "if (mode_colab is True):\n",
        "    # Connect to googledrive\n",
        "    #if 'google.colab' in str(get_ipython()):\n",
        "    # Mount google drive to access files via colab\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/gdrive\")  \n",
        "    %cd /content/gdrive/MyDrive/    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WSTI343YKTXI"
      },
      "source": [
        "On colab, to run on GPU, select *GPU* from the navigation menu *Runtime/Change runtime type*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings and requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clone Spyrit package"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JYhnDHEs3tse"
      },
      "source": [
        "Clone and install spyrit package if not installed or move to spyrit folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSdFQCvlX3W"
      },
      "outputs": [],
      "source": [
        "# #%%capture\n",
        "install_spyrit = True\n",
        "if (mode_colab is True):\n",
        "    if install_spyrit is True:\n",
        "        # Clone and install\n",
        "        !git clone https://github.com/openspyrit/spyrit.git\n",
        "        %cd spyrit\n",
        "        !pip install -e .\n",
        "\n",
        "        # Checkout to ongoing branch\n",
        "        !git fetch --all\n",
        "        !pip install girder_client\n",
        "    else:\n",
        "        # cd to spyrit folder is already cloned in your drive\n",
        "        %cd /content/gdrive/MyDrive/Colab_Notebooks/openspyrit/spyrit\n",
        "\n",
        "    # Add paths for modules\n",
        "    import sys\n",
        "    sys.path.append('./spyrit/core')\n",
        "    sys.path.append('./spyrit/misc')\n",
        "    sys.path.append('./spyrit/tutorial')\n",
        "else:\n",
        "    # Change path to spyrit/\n",
        "    os.chdir('../..')\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqfE7ApzlX3X"
      },
      "outputs": [],
      "source": [
        "# Load spyrit modules\n",
        "from spyrit.core.meas import HadamSplit\n",
        "from spyrit.core.noise import NoNoise, Poisson, PoissonApproxGauss\n",
        "from spyrit.core.prep import SplitPoisson\n",
        "from spyrit.core.recon import PseudoInverse, PinvNet, DCNet\n",
        "from spyrit.core.nnet import Unet\n",
        "from spyrit.misc.statistics import Cov2Var, data_loaders_stl10, transform_gray_norm\n",
        "from spyrit.misc.disp import imagesc \n",
        "from spyrit.misc.sampling import meas2img2\n",
        "from spyrit.core.train import load_net"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download covariance and DCNet model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download full covariance matrix (default set to unit matrix):\n",
        "```\n",
        "├───stat\n",
        "│   ├───Average_64x64.npy\n",
        "│   ├───Cov_64x64.npy\n",
        "├───model\n",
        "│   ├───dc-net_unet_... .pth\n",
        "├───spirit\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (download_cov is True):\n",
        "    import girder_client\n",
        "\n",
        "    # api Rest url of the warehouse\n",
        "    url='https://pilot-warehouse.creatis.insa-lyon.fr/api/v1'\n",
        "    \n",
        "    # Generate the warehouse client\n",
        "    gc = girder_client.GirderClient(apiUrl=url)\n",
        "\n",
        "    #%% Download the covariance matrix and mean image\n",
        "    data_folder = './stat/'\n",
        "    dataId_list = [\n",
        "            '63935b624d15dd536f0484a5', # for reconstruction (imageNet, 64)\n",
        "            '63935a224d15dd536f048496', # for reconstruction (imageNet, 64)\n",
        "            ]\n",
        "    for dataId in dataId_list:\n",
        "        myfile = gc.getFile(dataId)\n",
        "        gc.downloadFile(dataId, data_folder + myfile['name'])\n",
        "\n",
        "    print(f'Created {data_folder}') \n",
        "    !ls $data_folder\n",
        "\n",
        "    #%% Download the models\n",
        "    data_folder = './model/'\n",
        "    dataId_list = [\n",
        "                #'644a38c985f48d3da07140ba', # N_rec = 64, M = 4095\n",
        "                '644a38c785f48d3da07140b7', # N_rec = 64, M = 1024\n",
        "                #'644a38c585f48d3da07140b4', # N_rec = 64, M = 512\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF4uhDERlX3Y"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "H = 64                          # Image height (assumed squared image)\n",
        "M = H**2 // 4                   # Num measurements = subsampled by factor 2\n",
        "B = 10                          # Batch size\n",
        "alpha = 100                     # ph/pixel max: number of counts\n",
        "load_cov = False                 # Load cov matrix (requires /stat/Cov_64x64.npy); \n",
        "                                # otherwise, set to unit matrix\n",
        "load_unet = True                # Load pretrained UNet denoising\n",
        "\n",
        "imgs_path = './spyrit/images'\n",
        "\n",
        "cov_name = './stat/Cov_64x64.npy'\n",
        "\n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMsSp9clX3Z"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a batch of images from the folder *spyrit/images*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID3xMtw4lX3Z"
      },
      "outputs": [],
      "source": [
        "# Create a transform for natural images to normalized grayscale image tensors\n",
        "transform = transform_gray_norm(img_size=H)\n",
        "\n",
        "# Create dataset and loader (expects class folder 'images/test/')\n",
        "dataset = torchvision.datasets.ImageFolder(root=imgs_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = min(B, len(dataset)))\n",
        "\n",
        "# Select image\n",
        "x0, _ = next(iter(dataloader))\n",
        "x0 = x0[1:6,:,:,:]\n",
        "x = x0.detach().clone()\n",
        "b,c,h,w = x.shape\n",
        "x = x.view(b*c,h*w)\n",
        "print(f'Shape of incoming image (b*c,h*w): {x.shape}')\n",
        "\n",
        "x_plot = x.view(-1,H,H).cpu().numpy()    \n",
        "imagesc(x_plot[0,:,:],'Ground-truth image normalized')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qOSh1COplX3a"
      },
      "source": [
        "## Neural network pipeline and operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WXHzhtF4lX3c"
      },
      "source": [
        "### Experimental data simulation: Split measurement, noise and raw measurement operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We adopt linear measurements using a Hadamard operator corrupted by Poisson noise."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GB8W8RQzlX3d"
      },
      "source": [
        "Data simulation in spyrit is done by using three operators from using *spyrit.core.meas*: image normalization, split measurements and noise perturbation. In the example below, this corresponds to the following steps:\n",
        "\n",
        "$$\n",
        "x \\xrightarrow[\\text{Step 1}]{\\text{NoNoise}} \\frac{x+1}{2} \\xrightarrow[\\text{Step 2}]{\\text{HadamSplit}} y=Px \\xrightarrow[\\text{Step 3}]{\\text{Poisson}} \\mathcal{P}(\\alpha y)\n",
        "$$\n",
        "\n",
        "- Step 1: Given an image $x$ between $[-1, 1]$, the image is first normalized between $[0, 1]$ as\n",
        "\n",
        "$$\n",
        "\\frac{x+1}{2}\n",
        "$$\n",
        "using *spyrit's* *spyrit.core.noise.NoNoise* operator.\n",
        "\n",
        "- Step 2: Split measurements $y$ are obtained via the linear operator $P$: \n",
        "\n",
        "$$\n",
        "y = Px = \n",
        "\\begin{pmatrix}\n",
        "H_{+} \\\\\n",
        "H_{-}\n",
        "\\end{pmatrix}x=\n",
        "\\begin{pmatrix}\n",
        "\\max(H, 0) \\\\\n",
        "\\max(0,-H)\n",
        "\\end{pmatrix}x\n",
        "$$\n",
        "\n",
        "where $H=(H_{+}-H_{-})$ is a Hadamard matrix. \n",
        "\n",
        "- Step 3: Data is finally perturbed by Poisson noise as\n",
        "\n",
        "$$\n",
        "\\tilde{y} = \\mathcal{P}(\\alpha y)\n",
        "$$\n",
        "\n",
        "using spirit's *spyrit.core.noise.Poisson* :\n",
        "```   \n",
        "    meas_op = HadamSplit(M, h, Ord),\n",
        "    noise = Poisson(meas_op, alpha)\n",
        "    y = noise(x)\n",
        "```\n",
        "where $M$ is the number of meas, $h$ the height, and $Ord$ the Ordering matrix for undersampling. Inheritage is used as \n",
        "```\n",
        "    Poisson(NoNoise)\n",
        "    NoNoise(nn.module) \n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpV1mA6UlX3d"
      },
      "outputs": [],
      "source": [
        "# Operators \n",
        "#\n",
        "# Order matrix with shape (H, H) used to compute the permutation matrix \n",
        "# (as undersampling taking the first rows only)\n",
        "try:\n",
        "    Cov  = np.load(cov_name)\n",
        "except:\n",
        "    Cov = np.eye(H*H)\n",
        "    print(f\"Cov matrix {cov_name} not found! Set to the identity\")\n",
        "    \n",
        "Ord = Cov2Var(Cov)\n",
        "\n",
        "# Measurement operator: \n",
        "# Computes linear measurements y=Px, where P is a linear operator (matrix) with positive entries      \n",
        "# such that P=[H_{+}; H_{-}]=[max(H,0); max(0,-H)], H=H_{+}-H_{-}\n",
        "meas_op = HadamSplit(M, H, Ord)\n",
        "\n",
        "# Simulates raw split measurements from images in the range [0,1] assuming images provided in range [-1,1]\n",
        "# y=0.5*H(1 + x)\n",
        "# noise = NoNoise(meas_op) # noiseless\n",
        "noise = Poisson(meas_op, alpha)\n",
        "\n",
        "# Simulate raw measurements (non neagative measurements)\n",
        "y = noise(x)\n",
        "print(f'Shape of simulated measurements y: {y.shape}')\n",
        "\n",
        "m_plot = y.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements y: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Simulated Measurement')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SslsO1b_DTnR"
      },
      "source": [
        "Note that measurements are positive, as expected experimentally. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2p8DIylX3e"
      },
      "source": [
        "### Preprocessing measurement operator \n",
        "Note that previous steps allow to simulate experimental split measurements, which only considers positive pixels. A fourth step is done in order to preprocess the raw data acquired with a split measurements operator\n",
        "\n",
        "$$\n",
        "y \\xrightarrow[\\text{Step 4}]{\\text{Prep}} m=\\frac{y_+-y_-}{\\alpha},\n",
        "$$\n",
        "\n",
        "where $y_+=H_+x$, which in spyrit is done with *spyrit.core.prep.SplitPoisson*\n",
        "```\n",
        "    prep = SplitPoisson(alpha, meas_op)\n",
        "    m = prep(y)\n",
        "```\n",
        "Now, measurements can be negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgT619gSlX3e"
      },
      "outputs": [],
      "source": [
        "# Preprocess the raw data acquired with split measurement operator assuming Poisson noise\n",
        "prep = SplitPoisson(alpha, meas_op)\n",
        "\n",
        "# Preprocessed data\n",
        "m = prep(y)\n",
        "print(f'Shape of preprocessed data m: {m.shape}')\n",
        "\n",
        "\n",
        "m_plot = m.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements m: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Preprocessed data')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GcPslBpQlX3f"
      },
      "source": [
        "### Reconstruction operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let $\\tilde{H}$ represent the retaining Hadamard patterns, the Hadamard coefficients $m$ are given in terms of the image $x$ as \n",
        "\n",
        "$$\n",
        "m=\\tilde{H}x.\n",
        "$$\n",
        "\n",
        "The Hadamard operator is orthogonal, so an unknown image $x$ can be recovered from the inverse Hadamard transform \n",
        "\n",
        "$$\n",
        "\\hat{x}=\\tilde{H}^{\\dagger}m.\n",
        "$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image reconstruction in spyrit comprises four steps (the last one is optional):\n",
        "\n",
        "1. Denoising\n",
        "\n",
        "2. Data completion\n",
        "\n",
        "3. Hadamard inverse transform\n",
        "\n",
        "4. Nonlinear postprocessing\n",
        "\n",
        "$$\n",
        "m\\in\\mathbb{R}^{M} \\xrightarrow[\\text{Denoising}]{\\text{Step 1}} y_1\\in\\mathbb{R}^{M} \\xrightarrow[\\text{Completion}]{\\text{Step 2}} y_2\\in\\mathbb{R}^{N-M} \\xrightarrow[\\text{Inverse}]{\\text{Step 3}} \\tilde{x}\\in\\mathbb{R}^{N} \\xrightarrow[\\text{Postprocessing}]{\\text{Step 4}} \\hat{x}\\in\\mathbb{R}^{N_x\\times N_y}\n",
        "$$\n",
        "\n",
        "In spyrit, the four steps are comprised inside *spyrit.core.recon.PinvNet* or *spyrit.core.recon.DCNet*, and are automatically handed for sigle-pixel imaging data. The denoising network in the nonlinear step in dealt by *spyrit.core.nnet.Unet* and must be defined :\n",
        "\n",
        "```\n",
        "    denoi = Unet()\n",
        "    dcnet_unet = DCNet(noise, prep, Cov, denoi)\n",
        "    z_dcnet = dcnet.reconstruct(y) \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0p_56QDlX3f"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse operator\n",
        "pinv = PseudoInverse()\n",
        "\n",
        "# Reconstruction\n",
        "z_pinv = pinv(m, meas_op)\n",
        "print(f'Shape of reconstructed image z: {z_pinv.shape}')\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h2BxcOglX3g"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse net\n",
        "\n",
        "# Reconstruction with for Core module (linear net)\n",
        "pinvnet = PinvNet(noise, prep)\n",
        " \n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pinvnet = pinvnet.to(device)\n",
        "\n",
        "x = x0.detach().clone()\n",
        "x = x.to(device)\n",
        "z_pinvnet = pinvnet(x)\n",
        "# z_pinvnet = pinvnet.reconstruct(y)\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mizgTbYlX3g"
      },
      "outputs": [],
      "source": [
        "# DCNet\n",
        "\n",
        "# Reconstruction with for DCNet (linear net + denoising net)\n",
        "dcnet = DCNet(noise, prep, Cov)\n",
        "\n",
        "#y = pinvnet.acquire(x)         # or equivalently here: y = dcnet.acquire(x)\n",
        "#m = pinvnet.meas2img(y)        # zero-padded images (after preprocessing)\n",
        "dcnet = dcnet.to(device)\n",
        "z_dcnet = dcnet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "#x_dcnet_2 = dcnet(x)   # another reconstruction, from the ground-truth image\n",
        "\n",
        "z_plot = z_dcnet.view(-1,H,H).cpu().numpy()\n",
        "imagesc(z_plot[0,:,:],'DCNet reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pretreined DC UNet (UNet denoising)\n",
        "denoi = Unet()\n",
        "dcnet_unet = DCNet(noise, prep, Cov, denoi)\n",
        "\n",
        "# Load previously trained model\n",
        "try:\n",
        "    model_path = \"./model/dc-net_unet_imagenet_var_N0_10_N_64_M_1024_epo_30_lr_0.001_sss_10_sdr_0.5_bs_256_reg_1e-07_light\"\n",
        "    #model_path = './model/dc-net_unet_stl10_N0_100_N_64_M_1024_epo_30_lr_0.001_sss_10_sdr_0.5_bs_512_reg_1e-07.pth'\n",
        "    #dcnet_unet.load_state_dict(torch.load(model_path), loa)\n",
        "    load_net(model_path, dcnet_unet, device, False)\n",
        "    \n",
        "    dcnet_unet = dcnet_unet.to(device)\n",
        "    with torch.no_grad():\n",
        "        z_dcunet = dcnet_unet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "\n",
        "    z_plot = z_dcunet.view(-1,H,H).detach().cpu().numpy()\n",
        "    imagesc(z_plot[0,:,:],'DC UNet reconstruction', show=False)\n",
        "except:\n",
        "    print(f'Model {model_path} not found!')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
