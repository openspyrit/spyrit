{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit/blob/demo_colab/spyrit/tutorial/tuto_core_2d_short.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mbA6mRJNlX3Q"
      },
      "source": [
        "# Tutorial 2D - Image reconstruction for single-pixel imaging\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial focuses on Bayesian inversion, a special type of inverse problem\n",
        "that aims at incorporating prior information in terms of model and data\n",
        "probabilities in the inversion process.\n",
        "\n",
        "It shows how to simulate data and perform image reconstruction with spyrit toolbox. \n",
        "For data simulation, it loads an image from ImageNet and simulated measurements based on \n",
        "an undersampled Hadamard operator. You can select number of counts and undersampled factor. \n",
        "\n",
        "Image reconstruction is preformed using the following methods: \n",
        "-    Pseudo-inverse\n",
        "-    PInvNet:        Linear net\n",
        "-    DCNet:          Data completion net with unit matrix denoising\n",
        "-    DCUNet:         Data completion with UNet denoising, trained on stl10 dataset.\n",
        "                    Refer to tuto_run_train_colab.ipynb for an example to train DCUNet.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr1uLAat4CWI"
      },
      "source": [
        "## Settings and requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set google colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BWsO227W3jZ_"
      },
      "source": [
        "Mount google drive to import modules spyrit modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNKXfDpdlX3U"
      },
      "outputs": [],
      "source": [
        "mode_colab = True\n",
        "if (mode_colab is True):\n",
        "    # Connect to googledrive\n",
        "    #if 'google.colab' in str(get_ipython()):\n",
        "    # Mount google drive to access files via colab\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/gdrive\")  \n",
        "    %cd /content/gdrive/MyDrive/    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WSTI343YKTXI"
      },
      "source": [
        "On colab, choose GPU at *Runtime/Change runtime type*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clone Spyrit package"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JYhnDHEs3tse"
      },
      "source": [
        "Clone and install spyrit package if not installed or move to spyrit folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSdFQCvlX3W"
      },
      "outputs": [],
      "source": [
        "# #%%capture\n",
        "install_spyrit = True\n",
        "if (mode_colab is True):\n",
        "    if install_spyrit is True:\n",
        "        # Clone and install\n",
        "        !git clone https://github.com/openspyrit/spyrit.git\n",
        "        %cd spyrit\n",
        "        !pip install -e .\n",
        "\n",
        "        # Checkout to ongoing branch\n",
        "        !git fetch --all\n",
        "        !git checkout demo_colab\n",
        "    else:\n",
        "        # cd to spyrit folder is already cloned in your drive\n",
        "        %cd /content/gdrive/MyDrive/Colab_Notebooks/openspyrit/spyrit\n",
        "\n",
        "    # Add paths for modules\n",
        "    import sys\n",
        "    sys.path.append('./spyrit/core')\n",
        "    sys.path.append('./spyrit/misc')\n",
        "    sys.path.append('./spyrit/tutorial')\n",
        "else:\n",
        "    # Change path to spyrit/\n",
        "    os.chdir('../..')\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqfE7ApzlX3X"
      },
      "outputs": [],
      "source": [
        "# Load spyrit modules\n",
        "from spyrit.core.meas import HadamSplit\n",
        "from spyrit.core.noise import NoNoise, Poisson, PoissonApproxGauss\n",
        "from spyrit.core.prep import SplitPoisson\n",
        "from spyrit.core.recon import PseudoInverse, PinvNet, DCNet\n",
        "from spyrit.core.nnet import Unet\n",
        "from spyrit.misc.statistics import Cov2Var, data_loaders_stl10, transform_gray_norm\n",
        "from spyrit.misc.disp import imagesc \n",
        "from spyrit.misc.sampling import meas2img2\n",
        "from spyrit.core.train import load_net"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download covariance matrix. Alternatively install *openspyrit/spas* package:\n",
        "```\n",
        "├───stats\n",
        "│   ├───Average_64x64.npy\n",
        "│   ├───Cov_64x64.npy\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_cov = True\n",
        "if (download_cov is True):\n",
        "    import girder_client\n",
        "\n",
        "    # api Rest url of the warehouse\n",
        "    url='https://pilot-warehouse.creatis.insa-lyon.fr/api/v1'\n",
        "    \n",
        "    # Generate the warehouse client\n",
        "    gc = girder_client.GirderClient(apiUrl=url)\n",
        "\n",
        "    #%% Download the covariance matrix and mean image\n",
        "    data_folder = './stat/'\n",
        "    dataId_list = [\n",
        "            '63935b624d15dd536f0484a5', # for reconstruction (imageNet, 64)\n",
        "            '63935a224d15dd536f048496', # for reconstruction (imageNet, 64)\n",
        "            ]\n",
        "    for dataId in dataId_list:\n",
        "        myfile = gc.getFile(dataId)\n",
        "        gc.downloadFile(dataId, data_folder + myfile['name'])\n",
        "\n",
        "    print(f'Created {data_folder}') \n",
        "    !ls $data_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF4uhDERlX3Y"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "H = 64                          # Image height (assumed squared image)\n",
        "M = H**2 // 4                   # Num measurements = subsampled by factor 2\n",
        "B = 10                          # Batch size\n",
        "alpha = 100                     # ph/pixel max: number of counts\n",
        "load_cov = True                 # Load cov matrix (requires /stat/Cov_64x64.npy); \n",
        "                                # otherwise, set to unit matrix\n",
        "load_unet = True                # Load pretrained UNet denoising\n",
        "\n",
        "imgs_path = './spyrit/images'\n",
        "\n",
        "cov_name = './stat/Cov_64x64.npy'\n",
        "\n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMsSp9clX3Z"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID3xMtw4lX3Z"
      },
      "outputs": [],
      "source": [
        "# Create a transform for natural images to normalized grayscale image tensors\n",
        "transform = transform_gray_norm(img_size=H)\n",
        "\n",
        "# Create dataset and loader (expects class folder 'images/test/')\n",
        "dataset = torchvision.datasets.ImageFolder(root=imgs_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = min(B, len(dataset)))\n",
        "\n",
        "# Select image\n",
        "x0, _ = next(iter(dataloader))\n",
        "x0 = x0[1:6,:,:,:]\n",
        "x = x0.detach().clone()\n",
        "b,c,h,w = x.shape\n",
        "x = x.view(b*c,h*w)\n",
        "print(f'Shape of incoming image (b*c,h*w): {x.shape}')\n",
        "\n",
        "x_plot = x.view(-1,H,H).cpu().numpy()    \n",
        "imagesc(x_plot[0,:,:],'Ground-truth image normalized')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qOSh1COplX3a"
      },
      "source": [
        "## Operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0an9DxzMlX3a"
      },
      "source": [
        "Data simulation comprises three steps:\n",
        "\n",
        "1. Split Linear Measurements\n",
        "\n",
        "2. Noisy/Noisy raw measurements (handling negative images)\n",
        "\n",
        "3. Preprocess measurements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOMS1USulX3c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Data Simulation:\n",
        "    1) Split Linear Measurements:\n",
        "            y = Px = [H_{+}; H_{-}]x\n",
        "        \n",
        "        spyrit.core.meas\n",
        "        meas_op = LinearSplit(H), matrix H\n",
        "        meas_op = HadamSplit(M, h, Ord), M:#meas, h=height, Ord=Ordering matrix for undersampling\n",
        "\n",
        "        y = meas_op(x)\n",
        "\n",
        "    2) No Noisy/Noisy raw measurements (handling negative images):\n",
        "        Handles the fact that images are between [-1, 1] and construct measurements \n",
        "        from measurements operator.\n",
        "        Simulates raw measurements as expected by the single pixel camera (no negative measurements)\n",
        "\n",
        "        Noiseless:\n",
        "                y = 0.5*H(1+x)\n",
        "\n",
        "            spyrit.core.noise\n",
        "            meas_op = HadamSplit(M, h, Ord)\n",
        "            y = NoNoise(meas_op)(x) \n",
        "\n",
        "        Noisy:\n",
        "                y = Poisson((alpha/2)*H(1+x))\n",
        "\n",
        "            spyrit.core.noise\n",
        "            meas_op = HadamSplit(M, h, Ord)    \n",
        "            y = Poisson(meas_op, alpha)(x)\n",
        "\n",
        "    3) Preprocess measurements (before reconstruction): \n",
        "        Proceprocess to compensates for image normalization and splitting\n",
        "        Mixes split measurements.\n",
        "            m = (y+ - y-)/alpha - H*I\n",
        "        \n",
        "            spyrit.core.prep\n",
        "            meas_op = HadamSplit(M, h, Ord)    \n",
        "            m = SplitPoisson(alpha, meas_op)(y)\n",
        "\n",
        "    4) Reconstruct\n",
        "\n",
        "        Standard reconstruction:\n",
        "            z = PseudoInverse()(m, meas_op)\n",
        "        \n",
        "        Inverse Net:\n",
        "            Noiseless:\n",
        "            pinv_net = PinvNet(NoNoise(meas_op), SplitPoisson(alpha, meas_op))\n",
        "            z = pinv_net(x)\n",
        "\n",
        "            Noisy:\n",
        "            pinv_net = PinvNet(Poisson(meas_op, alpha), SplitPoisson(alpha, meas_op))\n",
        "            z_invnet = pinv_net.reconstruct(y)\n",
        "\n",
        "        DCNet:\n",
        "            dcnet = DCNet(Poisson(meas_op, alpha), SplitPoisson(alpha, meas_op), Cov)\n",
        "            y = dcnet.acquire(x) \n",
        "            z_dc = dcnet.reconstruct(y)\n",
        "            \"\"\"\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WXHzhtF4lX3c"
      },
      "source": [
        "### Split measurement and raw measurement operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GB8W8RQzlX3d"
      },
      "source": [
        "Split Linear Measurements:\n",
        "$$\n",
        "y = Px = [H_{+}; H_{-}]x\n",
        "$$\n",
        "\n",
        "Uses *spyrit.core.meas*\n",
        "\n",
        "```\n",
        "    meas_op = LinearSplit(H), \n",
        "    meas_op = HadamSplit(M, h, Ord), matrix for undersampling\n",
        "    y = meas_op(x)\n",
        "```\n",
        "foir linear matrix $H$ and $M$ is the number of meas, $h$ the height, and $Ord$ the Ordering matrix for undersampling. \n",
        "\n",
        "Below, we create the measurement and noise operators and then compute measurements as:\n",
        "```\n",
        "meas_op = HadamSplit(M, H, Ord)\n",
        "noise = Poisson(meas_op, alpha)\n",
        "y = noise(x)\n",
        "```\n",
        "where inheritage is used\n",
        "```\n",
        "Poisson(NoNoise)\n",
        "NoNoise(nn.module) \n",
        "```\n",
        "and\n",
        "\n",
        "$$\n",
        "x \\xrightarrow[]{\\text{NoNoise}} \\frac{x+1}{2} \\xrightarrow[\\text{meas\\_op}]{\\text{LinearSplit}} Px \\xrightarrow[]{\\text{Poisson}} y\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpV1mA6UlX3d"
      },
      "outputs": [],
      "source": [
        "# Operators \n",
        "#\n",
        "# Order matrix with shape (H, H) used to compute the permutation matrix \n",
        "# (as undersampling taking the first rows only)\n",
        "try:\n",
        "    Cov  = np.load(cov_name)\n",
        "except:\n",
        "    Cov = np.eye(H*H)\n",
        "    print(f\"Cov matrix {cov_name} not found! Set to the identity\")\n",
        "    \n",
        "Ord = Cov2Var(Cov)\n",
        "\n",
        "# Measurement operator: \n",
        "# Computes linear measurements y=Px, where P is a linear operator (matrix) with positive entries      \n",
        "# such that P=[H_{+}; H_{-}]=[max(H,0); max(0,-H)], H=H_{+}-H_{-}\n",
        "meas_op = HadamSplit(M, H, Ord)\n",
        "\n",
        "# Simulates raw split measurements from images in the range [0,1] assuming images provided in range [-1,1]\n",
        "# y=0.5*H(1 + x)\n",
        "# noise = NoNoise(meas_op) # noiseless\n",
        "noise = Poisson(meas_op, alpha)\n",
        "\n",
        "# Simulate raw measurements (non neagative measurements)\n",
        "y = noise(x)\n",
        "print(f'Shape of simulated measurements y: {y.shape}')\n",
        "\n",
        "m_plot = y.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements y: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Simulated Measurement')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SslsO1b_DTnR"
      },
      "source": [
        "Note that measurements are positive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2p8DIylX3e"
      },
      "source": [
        "### Preprocess measurement operator "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dWWx6K_8lX3e"
      },
      "source": [
        "Proceprocess to compensates for image normalization and splitting. It mixes split measurements:\n",
        "$$\n",
        "m = \\frac{y_+ - y_-}{\\alpha} - H*I\n",
        "$$\n",
        "\n",
        "Uses *spyrit.core.prep*\n",
        "```\n",
        "    meas_op = HadamSplit(M, h, Ord)    \n",
        "    m = SplitPoisson(alpha, meas_op)(y)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgT619gSlX3e"
      },
      "outputs": [],
      "source": [
        "# Preprocess the raw data acquired with split measurement operator assuming Poisson noise\n",
        "prep = SplitPoisson(alpha, meas_op)\n",
        "\n",
        "# Preprocessed data\n",
        "m = prep(y)\n",
        "print(f'Shape of preprocessed data m: {m.shape}')\n",
        "\n",
        "\n",
        "m_plot = m.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements m: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Preprocessed data')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AMj-XWVKDegZ"
      },
      "source": [
        "Now, measurements can be negative"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GcPslBpQlX3f"
      },
      "source": [
        "### Reconstruction operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0p_56QDlX3f"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse operator\n",
        "pinv = PseudoInverse()\n",
        "\n",
        "# Reconstruction\n",
        "z_pinv = pinv(m, meas_op)\n",
        "print(f'Shape of reconstructed image z: {z_pinv.shape}')\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h2BxcOglX3g"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse net\n",
        "\n",
        "# Reconstruction with for Core module (linear net)\n",
        "pinvnet = PinvNet(noise, prep)\n",
        " \n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pinvnet = pinvnet.to(device)\n",
        "\n",
        "x = x0.detach().clone()\n",
        "x = x.to(device)\n",
        "z_pinvnet = pinvnet(x)\n",
        "# z_pinvnet = pinvnet.reconstruct(y)\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mizgTbYlX3g"
      },
      "outputs": [],
      "source": [
        "# DCNet\n",
        "\n",
        "# Reconstruction with for DCNet (linear net + denoising net)\n",
        "dcnet = DCNet(noise, prep, Cov)\n",
        "\n",
        "#y = pinvnet.acquire(x)         # or equivalently here: y = dcnet.acquire(x)\n",
        "#m = pinvnet.meas2img(y)        # zero-padded images (after preprocessing)\n",
        "dcnet = dcnet.to(device)\n",
        "z_dcnet = dcnet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "#x_dcnet_2 = dcnet(x)   # another reconstruction, from the ground-truth image\n",
        "\n",
        "z_plot = z_dcnet.view(-1,H,H).cpu().numpy()\n",
        "imagesc(z_plot[0,:,:],'DCNet reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pretreined DC UNet (UNet denoising)\n",
        "denoi = Unet()\n",
        "dcnet_unet = DCNet(noise, prep, Cov, denoi)\n",
        "\n",
        "# Load previously trained model\n",
        "try:\n",
        "    model_path = \"./model/dc-net_unet_imagenet_var_N0_10_N_64_M_1024_epo_30_lr_0.001_sss_10_sdr_0.5_bs_256_reg_1e-07_light\"\n",
        "    #model_path = './model/dc-net_unet_stl10_N0_100_N_64_M_1024_epo_30_lr_0.001_sss_10_sdr_0.5_bs_512_reg_1e-07.pth'\n",
        "    #dcnet_unet.load_state_dict(torch.load(model_path), loa)\n",
        "    load_net(model_path, dcnet_unet, device, False)\n",
        "    \n",
        "    dcnet_unet = dcnet_unet.to(device)\n",
        "    with torch.no_grad():\n",
        "        z_dcunet = dcnet_unet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "\n",
        "    z_plot = z_dcunet.view(-1,H,H).detach().cpu().numpy()\n",
        "    imagesc(z_plot[0,:,:],'DC UNet reconstruction', show=False)\n",
        "except:\n",
        "    print(f'Model {model_path} not found!')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
